import { useState, useRef, useEffect, useCallback } from 'react';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Mic, MicOff, Volume2, VolumeX, Phone, MessageSquare, Play, Pause, Wifi, WifiOff } from 'lucide-react';
import { useToast } from '@/hooks/use-toast';

interface VoiceSupportProps {
  currentLanguage: string;
}

interface VoiceQuery {
  id: string;
  query: string;
  response: string;
  timestamp: Date;
  language: string;
  category: 'farming' | 'weather' | 'scheme' | 'disease' | 'general';
}

const mockQueries: VoiceQuery[] = [
  {
    id: '1',
    query: 'à¤®à¥‡à¤°à¥€ à¤—à¥‡à¤¹à¥‚à¤‚ à¤•à¥€ à¤«à¤¸à¤² à¤®à¥‡à¤‚ à¤ªà¤¤à¥à¤¤à¥‡ à¤ªà¥€à¤²à¥‡ à¤¹à¥‹ à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚, à¤•à¥à¤¯à¤¾ à¤•à¤°à¥‚à¤‚?',
    response: 'à¤ªà¤¤à¥à¤¤à¥‹à¤‚ à¤•à¤¾ à¤ªà¥€à¤²à¤¾ à¤¹à¥‹à¤¨à¤¾ à¤¨à¤¾à¤‡à¤Ÿà¥à¤°à¥‹à¤œà¤¨ à¤•à¥€ à¤•à¤®à¥€ à¤¯à¤¾ à¤…à¤¤à¤¿à¤°à¤¿à¤•à¥à¤¤ à¤ªà¤¾à¤¨à¥€ à¤•à¤¾ à¤¸à¤‚à¤•à¥‡à¤¤ à¤¹à¥‹ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤¤à¥à¤°à¤‚à¤¤ à¤¯à¥‚à¤°à¤¿à¤¯à¤¾ à¤•à¤¾ à¤›à¤¿à¤¡à¤¼à¤•à¤¾à¤µ à¤•à¤°à¥‡à¤‚ à¤”à¤° à¤ªà¤¾à¤¨à¥€ à¤•à¥€ à¤®à¤¾à¤¤à¥à¤°à¤¾ à¤•à¤® à¤•à¤°à¥‡à¤‚à¥¤',
    timestamp: new Date(),
    language: 'hindi',
    category: 'disease'
  },
  {
    id: '2',
    query: 'What is the current MSP for rice?',
    response: 'The current MSP for common rice is â‚¹2,300 per quintal for Kharif 2024. You can sell your produce at the nearest procurement center.',
    timestamp: new Date(Date.now() - 3600000),
    language: 'english',
    category: 'scheme'
  }
];

const VoiceSupport = ({ currentLanguage }: VoiceSupportProps) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentPlayingId, setCurrentPlayingId] = useState<string | null>(null);
  const [currentQuery, setCurrentQuery] = useState('');
  const [voiceQueries, setVoiceQueries] = useState<VoiceQuery[]>(mockQueries);
  const [selectedLanguage, setSelectedLanguage] = useState('hindi');
  const [isConnected, setIsConnected] = useState(false);
  const [connectionStatus, setConnectionStatus] = useState<'disconnected' | 'connecting' | 'connected' | 'error'>('disconnected');
  const [audioQueue, setAudioQueue] = useState<string[]>([]);

  const wsRef = useRef<WebSocket | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const speechSynthesisRef = useRef<SpeechSynthesisUtterance | null>(null);
  const audioPlayerRef = useRef<HTMLAudioElement | null>(null);
  const { toast } = useToast();

  // Audio queue management effect
  useEffect(() => {
    if (audioQueue.length > 0 && !isPlaying) {
      setIsPlaying(true);
      const audioData = audioQueue[0];

      // Create a data URL for the WAV file and play it
      const audioSrc = `data:audio/wav;base64,${audioData}`;
      audioPlayerRef.current = new Audio(audioSrc);

      audioPlayerRef.current.play();

      audioPlayerRef.current.onended = () => {
        // Remove the played item from queue and allow next to play
        setAudioQueue(prev => prev.slice(1));
        setIsPlaying(false);
        setCurrentPlayingId(null);
      }; audioPlayerRef.current.onerror = (error) => {
        console.error('Audio playback error:', error);
        setAudioQueue(prev => prev.slice(1));
        setIsPlaying(false);
        setCurrentPlayingId(null);
        toast({
          title: "Audio Error",
          description: "Failed to play voice response",
          variant: "destructive"
        });
      };
    }
  }, [audioQueue, isPlaying, toast]);

  // WebSocket connection management
  const connectWebSocket = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) return;

    setConnectionStatus('connecting');
    const wsUrl = `ws://localhost:8000/ws/voice`;

    try {
      wsRef.current = new WebSocket(wsUrl);

      wsRef.current.onopen = () => {
        setConnectionStatus('connected');
        setIsConnected(true);
        toast({
          title: "Connected",
          description: "Voice assistant is ready",
        });
      };

      wsRef.current.onmessage = (event) => {
        try {
          if (typeof event.data === 'string') {
            // Handle JSON messages
            const data = JSON.parse(event.data);
            handleWebSocketMessage(data);
          } else if (event.data instanceof ArrayBuffer) {
            // Handle binary audio data (if any) - not expected with WAV format
          }
        } catch (error) {
          console.error('Error parsing WebSocket message:', error);
        }
      };

      wsRef.current.onclose = () => {
        setConnectionStatus('disconnected');
        setIsConnected(false);
        setIsRecording(false);
      };

      wsRef.current.onerror = (error) => {
        console.error('WebSocket error:', error);
        setConnectionStatus('error');
        setIsConnected(false);
        toast({
          title: "Connection Error",
          description: "Failed to connect to voice service",
          variant: "destructive"
        });
      };
    } catch (error) {
      console.error('Error creating WebSocket:', error);
      setConnectionStatus('error');
    }
  }, [toast]);

  const handleWebSocketMessage = (data: any) => {
    switch (data.type) {
      case 'partial_transcript':
        setCurrentQuery(data.text);
        break;

      case 'agent_response':
        const newQuery: VoiceQuery = {
          id: Date.now().toString(),
          query: currentQuery || 'Voice query',
          response: data.text,
          timestamp: new Date(),
          language: selectedLanguage,
          category: 'general'
        };
        setVoiceQueries(prev => [newQuery, ...prev]);
        setCurrentQuery('');
        break;

      case 'agent_audio_wav':
        // Handle complete WAV file from backend
        if (data.audio_data) {
          console.log('[DEBUG] Received complete WAV audio file');
          // Add to queue for sequential playback
          setAudioQueue(prev => [...prev, data.audio_data]);
        }
        break;

      case 'status':
        // Handle status updates (ready, listening, thinking, speaking)
        if (data.status === 'listening') {
          setCurrentQuery('Listening...');
        } else if (data.status === 'thinking') {
          setCurrentQuery('Processing...');
        } else if (data.status === 'speaking') {
          setCurrentQuery('');
        }
        break;

      case 'error':
        toast({
          title: "Voice Error",
          description: data.message || "An error occurred",
          variant: "destructive"
        });
        break;

      default:
        // Unknown message type - silently ignore
        break;
    }
  };

  // Auto-connect on component mount
  useEffect(() => {
    connectWebSocket();

    return () => {
      if (wsRef.current) {
        wsRef.current.close();
      }
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
    };
  }, [connectWebSocket]);

  const translations = {
    en: {
      title: 'Voice Support System',
      description: 'Get farming advice in your local language through voice interaction',
      voiceAssistant: 'Voice Assistant',
      assistantDescription: 'Ask questions about farming, weather, schemes, or diseases in Hindi, English, or regional languages',
      recording: 'Recording...',
      stopRecordingTap: 'Tap to stop recording',
      readyToHelp: 'Ready to Help',
      startVoiceQueryTap: 'Tap to start voice query',
      stopRecordingBtn: 'Stop Recording',
      startVoiceQueryBtn: 'Start Voice Query',
      supportedLanguages: 'Supported Languages',
      callExpert: 'Call Expert',
      textChat: 'Text Chat',
      recentQueries: 'Recent Queries',
      interactionHistory: 'Your voice interactions and responses',
      stopAudio: 'Stop Audio',
      playAudio: 'Play Audio',
      stop: 'Stop',
      share: 'Share',
      noQueries: 'No voice queries yet',
      startAsking: 'Start by asking a farming question'
    },
    hi: {
      title: 'à¤†à¤µà¤¾à¤œà¤¼ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤ªà¥à¤°à¤£à¤¾à¤²à¥€',
      description: 'à¤†à¤µà¤¾à¤œà¤¼ à¤‡à¤‚à¤Ÿà¤°à¥‡à¤•à¥à¤¶à¤¨ à¤•à¥‡ à¤®à¤¾à¤§à¥à¤¯à¤® à¤¸à¥‡ à¤…à¤ªà¤¨à¥€ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤­à¤¾à¤·à¤¾ à¤®à¥‡à¤‚ à¤•à¥ƒà¤·à¤¿ à¤¸à¤²à¤¾à¤¹ à¤ªà¥à¤°à¤¾à¤ªà¥à¤¤ à¤•à¤°à¥‡à¤‚',
      voiceAssistant: 'à¤†à¤µà¤¾à¤œà¤¼ à¤¸à¤¹à¤¾à¤¯à¤•',
      assistantDescription: 'à¤¹à¤¿à¤‚à¤¦à¥€, à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤¯à¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤°à¥€à¤¯ à¤­à¤¾à¤·à¤¾à¤“à¤‚ à¤®à¥‡à¤‚ à¤•à¥ƒà¤·à¤¿, à¤®à¥Œà¤¸à¤®, à¤¯à¥‹à¤œà¤¨à¤¾à¤“à¤‚ à¤¯à¤¾ à¤¬à¥€à¤®à¤¾à¤°à¤¿à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚',
      recording: 'à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤—...',
      stopRecordingTap: 'à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤— à¤°à¥‹à¤•à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤Ÿà¥ˆà¤ª à¤•à¤°à¥‡à¤‚',
      readyToHelp: 'à¤®à¤¦à¤¦ à¤•à¥‡ à¤²à¤¿à¤ à¤¤à¥ˆà¤¯à¤¾à¤°',
      startVoiceQueryTap: 'à¤†à¤µà¤¾à¤œà¤¼ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¶à¥à¤°à¥‚ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤Ÿà¥ˆà¤ª à¤•à¤°à¥‡à¤‚',
      stopRecordingBtn: 'à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤— à¤°à¥‹à¤•à¥‡à¤‚',
      startVoiceQueryBtn: 'à¤†à¤µà¤¾à¤œà¤¼ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚',
      supportedLanguages: 'à¤¸à¤®à¤°à¥à¤¥à¤¿à¤¤ à¤­à¤¾à¤·à¤¾à¤à¤‚',
      callExpert: 'à¤µà¤¿à¤¶à¥‡à¤·à¤œà¥à¤ž à¤•à¥‹ à¤•à¥‰à¤² à¤•à¤°à¥‡à¤‚',
      textChat: 'à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ à¤šà¥ˆà¤Ÿ',
      recentQueries: 'à¤¹à¤¾à¤² à¤•à¥€ à¤ªà¥‚à¤›à¤¤à¤¾à¤›',
      interactionHistory: 'à¤†à¤ªà¤•à¥€ à¤†à¤µà¤¾à¤œà¤¼ à¤‡à¤‚à¤Ÿà¤°à¥‡à¤•à¥à¤¶à¤¨ à¤”à¤° à¤œà¤µà¤¾à¤¬',
      stopAudio: 'à¤‘à¤¡à¤¿à¤¯à¥‹ à¤°à¥‹à¤•à¥‡à¤‚',
      playAudio: 'à¤‘à¤¡à¤¿à¤¯à¥‹ à¤šà¤²à¤¾à¤à¤‚',
      stop: 'à¤°à¥‹à¤•à¥‡à¤‚',
      share: 'à¤¸à¤¾à¤à¤¾ à¤•à¤°à¥‡à¤‚',
      noQueries: 'à¤…à¤­à¥€ à¤¤à¤• à¤•à¥‹à¤ˆ à¤†à¤µà¤¾à¤œà¤¼ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¨à¤¹à¥€à¤‚',
      startAsking: 'à¤•à¥ƒà¤·à¤¿ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¤•à¤° à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚'
    },
    te: {
      title: 'à°µà°¾à°¯à°¿à°¸à± à°®à°¦à±à°¦à°¤à± à°µà±à°¯à°µà°¸à±à°¥',
      description: 'à°µà°¾à°¯à°¿à°¸à± à°‡à°‚à°Ÿà°°à°¾à°•à±à°·à°¨à± à°¦à±à°µà°¾à°°à°¾ à°®à±€ à°¸à±à°¥à°¾à°¨à°¿à°• à°­à°¾à°·à°²à±‹ à°µà±à°¯à°µà°¸à°¾à°¯ à°¸à°²à°¹à°¾ à°ªà±Šà°‚à°¦à°‚à°¡à°¿',
      voiceAssistant: 'à°µà°¾à°¯à°¿à°¸à± à°…à°¸à°¿à°¸à±à°Ÿà±†à°‚à°Ÿà±',
      assistantDescription: 'à°¤à±†à°²à±à°—à±, à°¹à°¿à°‚à°¦à±€, à°‡à°‚à°—à±à°²à±€à°·à± à°®à°°à°¿à°¯à± à°ªà±à°°à°¾à°‚à°¤à±€à°¯ à°­à°¾à°·à°²à°²à±‹ à°µà±à°¯à°µà°¸à°¾à°¯à°‚, à°µà°¾à°¤à°¾à°µà°°à°£à°‚, à°ªà°¥à°•à°¾à°²à± à°²à±‡à°¦à°¾ à°µà±à°¯à°¾à°§à±à°² à°—à±à°°à°¿à°‚à°šà°¿ à°ªà±à°°à°¶à±à°¨à°²à± à°…à°¡à°—à°‚à°¡à°¿',
      recording: 'à°°à°¿à°•à°¾à°°à±à°¡à°¿à°‚à°—à±...',
      stopRecordingTap: 'à°°à°¿à°•à°¾à°°à±à°¡à°¿à°‚à°—à± à°†à°ªà°¡à°¾à°¨à°¿à°•à°¿ à°Ÿà°¾à°ªà± à°šà±‡à°¯à°‚à°¡à°¿',
      readyToHelp: 'à°¸à°¹à°¾à°¯à°¾à°¨à°¿à°•à°¿ à°¸à°¿à°¦à±à°§à°‚',
      startVoiceQueryTap: 'à°µà°¾à°¯à°¿à°¸à± à°ªà±à°°à°¶à±à°¨ à°ªà±à°°à°¾à°°à°‚à°­à°¿à°‚à°šà°¡à°¾à°¨à°¿à°•à°¿ à°Ÿà°¾à°ªà± à°šà±‡à°¯à°‚à°¡à°¿',
      stopRecordingBtn: 'à°°à°¿à°•à°¾à°°à±à°¡à°¿à°‚à°—à± à°†à°ªà°‚à°¡à°¿',
      startVoiceQueryBtn: 'à°µà°¾à°¯à°¿à°¸à± à°ªà±à°°à°¶à±à°¨ à°ªà±à°°à°¾à°°à°‚à°­à°¿à°‚à°šà°‚à°¡à°¿',
      supportedLanguages: 'à°®à°¦à±à°¦à°¤à± à°‰à°¨à±à°¨ à°­à°¾à°·à°²à±',
      callExpert: 'à°¨à°¿à°ªà±à°£à±à°¡à°¿à°•à°¿ à°•à°¾à°²à± à°šà±‡à°¯à°‚à°¡à°¿',
      textChat: 'à°Ÿà±†à°•à±à°¸à±à°Ÿà± à°šà°¾à°Ÿà±',
      recentQueries: 'à°‡à°Ÿà±€à°µà°²à°¿ à°ªà±à°°à°¶à±à°¨à°²à±',
      interactionHistory: 'à°®à±€ à°µà°¾à°¯à°¿à°¸à± à°‡à°‚à°Ÿà°°à°¾à°•à±à°·à°¨à±â€Œà°²à± à°®à°°à°¿à°¯à± à°ªà±à°°à°¤à°¿à°¸à±à°ªà°‚à°¦à°¨à°²à±',
      stopAudio: 'à°†à°¡à°¿à°¯à±‹ à°†à°ªà°‚à°¡à°¿',
      playAudio: 'à°†à°¡à°¿à°¯à±‹ à°ªà±à°²à±‡ à°šà±‡à°¯à°‚à°¡à°¿',
      stop: 'à°†à°ªà°‚à°¡à°¿',
      share: 'à°·à±‡à°°à± à°šà±‡à°¯à°‚à°¡à°¿',
      noQueries: 'à°‡à°‚à°•à°¾ à°µà°¾à°¯à°¿à°¸à± à°ªà±à°°à°¶à±à°¨à°²à± à°²à±‡à°µà±',
      startAsking: 'à°µà±à°¯à°µà°¸à°¾à°¯ à°ªà±à°°à°¶à±à°¨ à°…à°¡à°¿à°—à°¿ à°ªà±à°°à°¾à°°à°‚à°­à°¿à°‚à°šà°‚à°¡à°¿'
    },
    ta: {
      title: 'à®•à¯à®°à®²à¯ à®†à®¤à®°à®µà¯ à®…à®®à¯ˆà®ªà¯à®ªà¯',
      description: 'à®•à¯à®°à®²à¯ à®¤à¯Šà®Ÿà®°à¯à®ªà¯ à®®à¯‚à®²à®®à¯ à®‰à®™à¯à®•à®³à¯ à®‰à®³à¯à®³à¯‚à®°à¯ à®®à¯Šà®´à®¿à®¯à®¿à®²à¯ à®µà®¿à®µà®šà®¾à®¯ à®†à®²à¯‹à®šà®©à¯ˆ à®ªà¯†à®±à¯à®™à¯à®•à®³à¯',
      voiceAssistant: 'à®•à¯à®°à®²à¯ à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯',
      assistantDescription: 'à®¤à®®à®¿à®´à¯, à®‡à®¨à¯à®¤à®¿, à®†à®™à¯à®•à®¿à®²à®®à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®¿à®°à®¾à®¨à¯à®¤à®¿à®¯ à®®à¯Šà®´à®¿à®•à®³à®¿à®²à¯ à®µà®¿à®µà®šà®¾à®¯à®®à¯, à®µà®¾à®©à®¿à®²à¯ˆ, à®¤à®¿à®Ÿà¯à®Ÿà®™à¯à®•à®³à¯ à®…à®²à¯à®²à®¤à¯ à®¨à¯‹à®¯à¯à®•à®³à¯ à®ªà®±à¯à®±à®¿ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯ à®•à¯‡à®³à¯à®™à¯à®•à®³à¯',
      recording: 'à®ªà®¤à®¿à®µà¯ à®šà¯†à®¯à¯à®•à®¿à®±à®¤à¯...',
      stopRecordingTap: 'à®ªà®¤à®¿à®µà¯ à®¨à®¿à®±à¯à®¤à¯à®¤ à®¤à®Ÿà¯à®Ÿà®µà¯à®®à¯',
      readyToHelp: 'à®‰à®¤à®µà®¿à®•à¯à®•à¯ à®¤à®¯à®¾à®°à¯',
      startVoiceQueryTap: 'à®•à¯à®°à®²à¯ à®•à¯‡à®³à¯à®µà®¿ à®¤à¯Šà®Ÿà®™à¯à®• à®¤à®Ÿà¯à®Ÿà®µà¯à®®à¯',
      stopRecordingBtn: 'à®ªà®¤à®¿à®µà¯ à®¨à®¿à®±à¯à®¤à¯à®¤à¯',
      startVoiceQueryBtn: 'à®•à¯à®°à®²à¯ à®•à¯‡à®³à¯à®µà®¿ à®¤à¯Šà®Ÿà®™à¯à®•à¯',
      supportedLanguages: 'à®†à®¤à®°à®¿à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®®à¯ à®®à¯Šà®´à®¿à®•à®³à¯',
      callExpert: 'à®¨à®¿à®ªà¯à®£à®°à¯ˆ à®…à®´à¯ˆà®•à¯à®•à®µà¯à®®à¯',
      textChat: 'à®‰à®°à¯ˆ à®…à®°à®Ÿà¯à®Ÿà¯ˆ',
      recentQueries: 'à®šà®®à¯€à®ªà®¤à¯à®¤à®¿à®¯ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯',
      interactionHistory: 'à®‰à®™à¯à®•à®³à¯ à®•à¯à®°à®²à¯ à®¤à¯Šà®Ÿà®°à¯à®ªà¯à®•à®³à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®¤à®¿à®²à¯à®•à®³à¯',
      stopAudio: 'à®†à®Ÿà®¿à®¯à¯‹ à®¨à®¿à®±à¯à®¤à¯à®¤à¯',
      playAudio: 'à®†à®Ÿà®¿à®¯à¯‹ à®‡à®¯à®•à¯à®•à¯',
      stop: 'à®¨à®¿à®±à¯à®¤à¯à®¤à¯',
      share: 'à®ªà®•à®¿à®°à¯',
      noQueries: 'à®‡à®©à¯à®©à¯à®®à¯ à®•à¯à®°à®²à¯ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯ à®‡à®²à¯à®²à¯ˆ',
      startAsking: 'à®µà®¿à®µà®šà®¾à®¯ à®•à¯‡à®³à¯à®µà®¿ à®•à¯‡à®Ÿà¯à®Ÿà¯ à®¤à¯Šà®Ÿà®™à¯à®•à¯à®™à¯à®•à®³à¯'
    },
    ml: {
      title: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´¸à´ªàµà´ªàµ‹àµ¼à´Ÿàµà´Ÿàµ à´¸à´¿à´¸àµà´±àµà´±à´‚',
      description: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´‡à´¨àµà´±à´±à´¾à´•àµà´·àµ» à´µà´´à´¿ à´¨à´¿à´™àµà´™à´³àµà´Ÿàµ† à´ªàµà´°à´¾à´¦àµ‡à´¶à´¿à´• à´­à´¾à´·à´¯à´¿àµ½ à´•àµƒà´·à´¿ à´‰à´ªà´¦àµ‡à´¶à´‚ à´¨àµ‡à´Ÿàµà´•',
      voiceAssistant: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´…à´¸à´¿à´¸àµà´±àµà´±à´¨àµà´±àµ',
      assistantDescription: 'à´®à´²à´¯à´¾à´³à´‚, à´¹à´¿à´¨àµà´¦à´¿, à´‡à´‚à´—àµà´²àµ€à´·àµ, à´ªàµà´°à´¾à´¦àµ‡à´¶à´¿à´• à´­à´¾à´·à´•à´³à´¿àµ½ à´•àµƒà´·à´¿, à´•à´¾à´²à´¾à´µà´¸àµà´¥, à´ªà´¦àµà´§à´¤à´¿à´•àµ¾, à´°àµ‹à´—à´™àµà´™àµ¾ à´Žà´¨àµà´¨à´¿à´µà´¯àµ†à´•àµà´•àµà´±à´¿à´šàµà´šàµ à´šàµ‹à´¦àµà´¯à´™àµà´™àµ¾ à´šàµ‹à´¦à´¿à´•àµà´•àµà´•',
      recording: 'à´±àµ†à´•àµà´•àµ‹àµ¼à´¡à´¿à´‚à´—àµ...',
      stopRecordingTap: 'à´±àµ†à´•àµà´•àµ‹àµ¼à´¡à´¿à´‚à´—àµ à´¨à´¿àµ¼à´¤àµà´¤à´¾àµ» à´Ÿà´¾à´ªàµà´ªàµ à´šàµ†à´¯àµà´¯àµà´•',
      readyToHelp: 'à´¸à´¹à´¾à´¯à´¤àµà´¤à´¿à´¨àµ à´¤à´¯àµà´¯à´¾àµ¼',
      startVoiceQueryTap: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´šàµ‹à´¦àµà´¯à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´Ÿà´¾à´ªàµà´ªàµ à´šàµ†à´¯àµà´¯àµà´•',
      stopRecordingBtn: 'à´±àµ†à´•àµà´•àµ‹àµ¼à´¡à´¿à´‚à´—àµ à´¨à´¿àµ¼à´¤àµà´¤àµà´•',
      startVoiceQueryBtn: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´šàµ‹à´¦àµà´¯à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•àµà´•',
      supportedLanguages: 'à´ªà´¿à´¨àµà´¤àµà´£à´¯àµà´³àµà´³ à´­à´¾à´·à´•àµ¾',
      callExpert: 'à´µà´¿à´¦à´—àµà´§à´¨àµ† à´µà´¿à´³à´¿à´•àµà´•àµà´•',
      textChat: 'à´Ÿàµ†à´•àµà´¸àµà´±àµà´±àµ à´šà´¾à´±àµà´±àµ',
      recentQueries: 'à´¸à´®àµ€à´ªà´•à´¾à´² à´šàµ‹à´¦àµà´¯à´™àµà´™àµ¾',
      interactionHistory: 'à´¨à´¿à´™àµà´™à´³àµà´Ÿàµ† à´µàµ‹à´¯àµâ€Œà´¸àµ à´‡à´¨àµà´±à´±à´¾à´•àµà´·à´¨àµà´•à´³àµà´‚ à´ªàµà´°à´¤à´¿à´•à´°à´£à´™àµà´™à´³àµà´‚',
      stopAudio: 'à´“à´¡à´¿à´¯àµ‹ à´¨à´¿àµ¼à´¤àµà´¤àµà´•',
      playAudio: 'à´“à´¡à´¿à´¯àµ‹ à´ªàµà´²àµ‡ à´šàµ†à´¯àµà´¯àµà´•',
      stop: 'à´¨à´¿àµ¼à´¤àµà´¤àµà´•',
      share: 'à´ªà´™àµà´•à´¿à´Ÿàµà´•',
      noQueries: 'à´‡à´¤àµà´µà´°àµ† à´µàµ‹à´¯àµâ€Œà´¸àµ à´šàµ‹à´¦àµà´¯à´™àµà´™à´³à´¿à´²àµà´²',
      startAsking: 'à´’à´°àµ à´•àµƒà´·à´¿ à´šàµ‹à´¦àµà´¯à´‚ à´šàµ‹à´¦à´¿à´šàµà´šàµ à´†à´°à´‚à´­à´¿à´•àµà´•àµà´•'
    }
  };

  const t = translations[currentLanguage as keyof typeof translations] || translations.en;

  const handleStartRecording = async () => {
    if (!isConnected) {
      toast({
        title: "Not Connected",
        description: "Please wait for voice service to connect",
        variant: "destructive"
      });
      return;
    }

    try {
      // Get microphone access - let browser use its preferred sample rate
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,        // Mono audio
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
          // Remove sampleRate constraint - let browser choose (usually 48kHz)
        }
      });

      // Create AudioContext for raw PCM processing
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);

      // Create ScriptProcessor for raw audio data
      const processor = audioContext.createScriptProcessor(1024, 1, 1);

      processor.onaudioprocess = (event) => {
        if (wsRef.current?.readyState === WebSocket.OPEN) {
          const inputData = event.inputBuffer.getChannelData(0);

          // Convert float32 to int16 PCM
          const pcmData = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            // Convert from [-1, 1] float to [-32768, 32767] int16
            pcmData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32767));
          }

          // Send raw PCM data as binary
          wsRef.current.send(pcmData.buffer);
        }
      };

      // Connect the audio processing chain
      source.connect(processor);
      processor.connect(audioContext.destination);

      // Store references for cleanup
      mediaRecorderRef.current = {
        stop: () => {
          processor.disconnect();
          source.disconnect();
          audioContext.close();
          stream.getTracks().forEach(track => track.stop());
        },
        state: 'recording'
      } as any;
      setIsRecording(true);

      toast({
        title: "Recording Started",
        description: "Speak your farming question clearly",
      });
    } catch (error) {
      console.error('Error starting recording:', error);
      toast({
        title: "Recording Error",
        description: "Could not access microphone. Please check permissions.",
        variant: "destructive"
      });
    }
  };

  const handleStopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
    setIsRecording(false);

    toast({
      title: "Processing",
      description: "Analyzing your question...",
    });
  };

  const handlePlayResponse = (query: VoiceQuery) => {
    // Stop any currently playing audio
    if (isPlaying) {
      handleStopAudio();
      return;
    }

    setIsPlaying(true);
    setCurrentPlayingId(query.id);

    // Use Web Speech API for text-to-speech if available
    if ('speechSynthesis' in window) {
      // Cancel any existing speech
      speechSynthesis.cancel();

      const utterance = new SpeechSynthesisUtterance(query.response);
      utterance.lang = query.language === 'hindi' ? 'hi-IN' : 'en-IN';
      utterance.rate = 0.9; // Slightly slower for better comprehension
      utterance.pitch = 1;
      utterance.volume = 1;

      utterance.onend = () => {
        setIsPlaying(false);
        setCurrentPlayingId(null);
        speechSynthesisRef.current = null;
      };

      utterance.onerror = () => {
        setIsPlaying(false);
        setCurrentPlayingId(null);
        speechSynthesisRef.current = null;
        toast({
          title: "Audio Error",
          description: "Failed to play audio response",
          variant: "destructive"
        });
      };

      speechSynthesisRef.current = utterance;
      speechSynthesis.speak(utterance);
    } else {
      // Fallback simulation
      setTimeout(() => {
        setIsPlaying(false);
        setCurrentPlayingId(null);
      }, 3000);
    }

    toast({
      title: "Playing Response",
      description: `Playing in ${query.language}`,
    });
  };

  const handleStopAudio = () => {
    if ('speechSynthesis' in window) {
      speechSynthesis.cancel();
    }
    setIsPlaying(false);
    setCurrentPlayingId(null);
    speechSynthesisRef.current = null;

    toast({
      title: "Audio Stopped",
      description: "Voice playback has been stopped",
    });
  };

  const getCategoryColor = (category: string) => {
    switch (category) {
      case 'farming': return 'bg-primary/10 text-primary';
      case 'weather': return 'bg-accent/10 text-accent';
      case 'scheme': return 'bg-secondary/10 text-secondary';
      case 'disease': return 'bg-destructive/10 text-destructive';
      default: return 'bg-muted text-muted-foreground';
    }
  };

  return (
    <div className="space-y-6" id="support">
      <div className="text-center space-y-2">
        <h2 className="text-3xl font-bold text-primary">{t.title}</h2>
        <p className="text-muted-foreground">
          {t.description}
        </p>
      </div>

      <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
        {/* Voice Input Section */}
        <Card className="hover:shadow-lg transition-all duration-300">
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <Mic className="w-5 h-5 text-primary" />
              {t.voiceAssistant}
              <div className="ml-auto flex items-center gap-1">
                {connectionStatus === 'connected' ? (
                  <Wifi className="w-4 h-4 text-green-500" />
                ) : connectionStatus === 'connecting' ? (
                  <Wifi className="w-4 h-4 text-yellow-500 animate-pulse" />
                ) : (
                  <WifiOff className="w-4 h-4 text-red-500" />
                )}
                <span className={`text-xs ${connectionStatus === 'connected' ? 'text-green-500' :
                  connectionStatus === 'connecting' ? 'text-yellow-500' : 'text-red-500'
                  }`}>
                  {connectionStatus}
                </span>
              </div>
            </CardTitle>
            <CardDescription>
              {t.assistantDescription}
            </CardDescription>
          </CardHeader>
          <CardContent className="space-y-6">
            {/* Recording Interface */}
            <div className="text-center space-y-4">
              <div className={`w-24 h-24 mx-auto rounded-full flex items-center justify-center transition-all duration-300 ${isRecording
                ? 'bg-destructive/20 border-4 border-destructive animate-pulse'
                : 'bg-primary/20 border-4 border-primary hover:bg-primary/30'
                }`}>
                {isRecording ? (
                  <MicOff className="w-8 h-8 text-destructive" />
                ) : (
                  <Mic className="w-8 h-8 text-primary" />
                )}
              </div>

              <div className="space-y-2">
                {isRecording ? (
                  <>
                    <p className="text-lg font-medium text-destructive">{t.recording}</p>
                    <p className="text-sm text-muted-foreground">{t.stopRecordingTap}</p>
                  </>
                ) : (
                  <>
                    <p className="text-lg font-medium">{t.readyToHelp}</p>
                    <p className="text-sm text-muted-foreground">{t.startVoiceQueryTap}</p>
                  </>
                )}
              </div>

              <Button
                size="lg"
                variant={isRecording ? "destructive" : "hero"}
                onClick={isRecording ? handleStopRecording : handleStartRecording}
                className="w-full"
              >
                {isRecording ? (
                  <>
                    <MicOff className="w-4 h-4 mr-2" />
                    {t.stopRecordingBtn}
                  </>
                ) : (
                  <>
                    <Mic className="w-4 h-4 mr-2" />
                    {t.startVoiceQueryBtn}
                  </>
                )}
              </Button>
            </div>

            {/* Current Query Display */}
            {currentQuery && (
              <div className="bg-muted/50 p-3 rounded-lg border">
                <p className="text-sm font-medium text-muted-foreground mb-1">Current Query:</p>
                <p className="text-sm">{currentQuery}</p>
              </div>
            )}

            {/* Language Selection */}
            <div className="space-y-2">
              <h4 className="font-medium">{t.supportedLanguages}</h4>
              <div className="flex flex-wrap gap-2">
                {[
                  { code: 'hindi', name: 'à¤¹à¤¿à¤¨à¥à¤¦à¥€', flag: 'ðŸ‡®ðŸ‡³' },
                  { code: 'english', name: 'English', flag: 'ðŸ‡¬ðŸ‡§' },
                  { code: 'punjabi', name: 'à¨ªà©°à¨œà¨¾à¨¬à©€', flag: 'ðŸ‡®ðŸ‡³' },
                  { code: 'telugu', name: 'à°¤à±†à°²à±à°—à±', flag: 'ðŸ‡®ðŸ‡³' },
                  { code: 'tamil', name: 'à®¤à®®à®¿à®´à¯', flag: 'ðŸ‡®ðŸ‡³' },
                ].map((lang) => (
                  <Button
                    key={lang.code}
                    variant={selectedLanguage === lang.code ? "default" : "outline"}
                    size="sm"
                    onClick={() => setSelectedLanguage(lang.code)}
                  >
                    {lang.flag} {lang.name}
                  </Button>
                ))}
              </div>
            </div>

            {/* Quick Actions */}
            <div className="grid grid-cols-2 gap-2">
              <Button variant="outline" size="sm">
                <Phone className="w-4 h-4 mr-2" />
                {t.callExpert}
              </Button>
              <Button variant="outline" size="sm">
                <MessageSquare className="w-4 h-4 mr-2" />
                {t.textChat}
              </Button>
            </div>
          </CardContent>
        </Card>

        {/* Query History */}
        <Card className="hover:shadow-lg transition-all duration-300">
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <MessageSquare className="w-5 h-5 text-accent" />
              {t.recentQueries}
            </CardTitle>
            <CardDescription>
              {t.interactionHistory}
            </CardDescription>
          </CardHeader>
          <CardContent className="space-y-4">
            {voiceQueries.length > 0 ? (
              voiceQueries.map((query) => (
                <div key={query.id} className="space-y-3 p-4 bg-muted/30 rounded-lg">
                  <div className="flex items-start justify-between">
                    <div className="space-y-1 flex-1">
                      <div className="flex items-center gap-2">
                        <Badge className={getCategoryColor(query.category)} variant="secondary">
                          {query.category}
                        </Badge>
                        <span className="text-xs text-muted-foreground">
                          {query.timestamp.toLocaleTimeString()}
                        </span>
                      </div>
                      <p className="text-sm font-medium">{query.query}</p>
                    </div>
                  </div>

                  <div className="bg-primary/5 p-3 rounded border-l-4 border-primary">
                    <p className="text-sm">{query.response}</p>
                  </div>

                  <div className="flex gap-2">
                    <Button
                      variant="outline"
                      size="sm"
                      onClick={() => handlePlayResponse(query)}
                    >
                      {isPlaying && currentPlayingId === query.id ? (
                        <>
                          <Pause className="w-3 h-3 mr-1" />
                          {t.stopAudio}
                        </>
                      ) : (
                        <>
                          <Volume2 className="w-3 h-3 mr-1" />
                          {t.playAudio}
                        </>
                      )}
                    </Button>
                    {isPlaying && currentPlayingId === query.id && (
                      <Button
                        variant="destructive"
                        size="sm"
                        onClick={handleStopAudio}
                      >
                        <VolumeX className="w-3 h-3 mr-1" />
                        {t.stop}
                      </Button>
                    )}
                    <Button variant="ghost" size="sm">
                      {t.share}
                    </Button>
                  </div>
                </div>
              ))
            ) : (
              <div className="text-center py-8 text-muted-foreground">
                <MessageSquare className="w-12 h-12 mx-auto mb-3 opacity-50" />
                <p>{t.noQueries}</p>
                <p className="text-sm mt-1">{t.startAsking}</p>
              </div>
            )}
          </CardContent>
        </Card>
      </div>
    </div>
  );
};

export default VoiceSupport;