import React, { useState, useRef } from 'react';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Mic, MicOff, Volume2, VolumeX, Phone, MessageSquare, Play, Pause } from 'lucide-react';
import { useToast } from '@/hooks/use-toast';

const VOICE_WS_URL = (import.meta as any)?.env?.VITE_VOICE_WS_URL || 'ws://127.0.0.1:8000/ws/voice';

interface VoiceSupportProps {
  currentLanguage: string;
}

interface VoiceQuery {
  id: string;
  query: string;
  response: string;
  timestamp: Date;
  language: string;
  category: 'farming' | 'weather' | 'scheme' | 'disease' | 'general';
}

const mockQueries: VoiceQuery[] = [
  {
    id: '1',
    query: 'à¤®à¥‡à¤°à¥€ à¤—à¥‡à¤¹à¥‚à¤‚ à¤•à¥€ à¤«à¤¸à¤² à¤®à¥‡à¤‚ à¤ªà¤¤à¥à¤¤à¥‡ à¤ªà¥€à¤²à¥‡ à¤¹à¥‹ à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚, à¤•à¥à¤¯à¤¾ à¤•à¤°à¥‚à¤‚?',
    response: 'à¤ªà¤¤à¥à¤¤à¥‹à¤‚ à¤•à¤¾ à¤ªà¥€à¤²à¤¾ à¤¹à¥‹à¤¨à¤¾ à¤¨à¤¾à¤‡à¤Ÿà¥à¤°à¥‹à¤œà¤¨ à¤•à¥€ à¤•à¤®à¥€ à¤¯à¤¾ à¤…à¤¤à¤¿à¤°à¤¿à¤•à¥à¤¤ à¤ªà¤¾à¤¨à¥€ à¤•à¤¾ à¤¸à¤‚à¤•à¥‡à¤¤ à¤¹à¥‹ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤¤à¥à¤°à¤‚à¤¤ à¤¯à¥‚à¤°à¤¿à¤¯à¤¾ à¤•à¤¾ à¤›à¤¿à¤¡à¤¼à¤•à¤¾à¤µ à¤•à¤°à¥‡à¤‚ à¤”à¤° à¤ªà¤¾à¤¨à¥€ à¤•à¥€ à¤®à¤¾à¤¤à¥à¤°à¤¾ à¤•à¤® à¤•à¤°à¥‡à¤‚à¥¤',
    timestamp: new Date(),
    language: 'hindi',
    category: 'disease'
  },
  {
    id: '2', 
    query: 'What is the current MSP for rice?',
    response: 'The current MSP for common rice is â‚¹2,300 per quintal for Kharif 2024. You can sell your produce at the nearest procurement center.',
    timestamp: new Date(Date.now() - 3600000),
    language: 'english',
    category: 'scheme'
  }
];

const VoiceSupport = ({ currentLanguage }: VoiceSupportProps) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentPlayingId, setCurrentPlayingId] = useState<string | null>(null);
  const [currentQuery, setCurrentQuery] = useState('');
  const [aiResponse, setAiResponse] = useState('');
  const [voiceQueries, setVoiceQueries] = useState<VoiceQuery[]>(mockQueries);
  const [selectedLanguage, setSelectedLanguage] = useState(currentLanguage || 'hindi');
  const speechSynthesisRef = useRef<SpeechSynthesisUtterance | null>(null);
  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const workletNodeRef = useRef<AudioWorkletNode | null>(null);
  const { toast } = useToast();

  // Function to play audio data received from Deepgram
  const playAudioData = (audioData: Uint8Array) => {
    try {
      console.log('Received audio data length:', audioData.length);
      
      // Create audio context for playback
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();

      // Deepgram Agent typically outputs PCM16 at 24kHz
      const sampleRate = 24000;
      
      // Convert Uint8Array to Int16Array (PCM16)
      const pcmData = new Int16Array(audioData.buffer);
      console.log('PCM data length:', pcmData.length);
      
      if (pcmData.length === 0) {
        console.warn('Empty audio data received');
        return;
      }
      
      // Convert PCM16 to Float32Array for Web Audio API
      const floatData = new Float32Array(pcmData.length);
      for (let i = 0; i < pcmData.length; i++) {
        floatData[i] = pcmData[i] / 32768.0; // Convert to [-1, 1] range
      }

      // Create audio buffer
      const audioBuffer = audioContext.createBuffer(1, floatData.length, sampleRate);
      audioBuffer.copyToChannel(floatData, 0);

      // Create source and play
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);
      
      source.onended = () => {
        console.log('Audio playback finished');
      };
      
      console.log('Starting audio playback...');
      source.start();

    } catch (error) {
      console.error('Error playing audio data:', error);
      
      // Fallback to browser TTS if audio playback fails
      if (aiResponse) {
        const utterance = new SpeechSynthesisUtterance(aiResponse);
        utterance.lang = selectedLanguage === 'hindi' ? 'hi-IN' : 'en-IN';
        speechSynthesis.speak(utterance);
      }
    }
  };

  const translations = {
    en: {
      title: 'Voice Support System',
      description: 'Get farming advice in your local language through voice interaction',
      voiceAssistant: 'Voice Assistant',
      assistantDescription: 'Ask questions about farming, weather, schemes, or diseases in Hindi, English, or regional languages',
      recording: 'Recording...',
      stopRecordingTap: 'Tap to stop recording',
      readyToHelp: 'Ready to Help',
      startVoiceQueryTap: 'Tap to start voice query',
      stopRecordingBtn: 'Stop Recording',
      startVoiceQueryBtn: 'Start Voice Query',
      supportedLanguages: 'Supported Languages',
      callExpert: 'Call Expert',
      textChat: 'Text Chat',
      recentQueries: 'Recent Queries',
      interactionHistory: 'Your voice interactions and responses',
      stopAudio: 'Stop Audio',
      playAudio: 'Play Audio',
      stop: 'Stop',
      share: 'Share',
      noQueries: 'No voice queries yet',
      startAsking: 'Start by asking a farming question'
    },
    hi: {
      title: 'à¤†à¤µà¤¾à¤œà¤¼ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤ªà¥à¤°à¤£à¤¾à¤²à¥€',
      description: 'à¤†à¤µà¤¾à¤œà¤¼ à¤‡à¤‚à¤Ÿà¤°à¥‡à¤•à¥à¤¶à¤¨ à¤•à¥‡ à¤®à¤¾à¤§à¥à¤¯à¤® à¤¸à¥‡ à¤…à¤ªà¤¨à¥€ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤­à¤¾à¤·à¤¾ à¤®à¥‡à¤‚ à¤•à¥ƒà¤·à¤¿ à¤¸à¤²à¤¾à¤¹ à¤ªà¥à¤°à¤¾à¤ªà¥à¤¤ à¤•à¤°à¥‡à¤‚',
      voiceAssistant: 'à¤†à¤µà¤¾à¤œà¤¼ à¤¸à¤¹à¤¾à¤¯à¤•',
      assistantDescription: 'à¤¹à¤¿à¤‚à¤¦à¥€, à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤¯à¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤°à¥€à¤¯ à¤­à¤¾à¤·à¤¾à¤“à¤‚ à¤®à¥‡à¤‚ à¤•à¥ƒà¤·à¤¿, à¤®à¥Œà¤¸à¤®, à¤¯à¥‹à¤œà¤¨à¤¾à¤“à¤‚ à¤¯à¤¾ à¤¬à¥€à¤®à¤¾à¤°à¤¿à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚',
      recording: 'à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤—...',
      stopRecordingTap: 'à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤— à¤°à¥‹à¤•à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤Ÿà¥ˆà¤ª à¤•à¤°à¥‡à¤‚',
      readyToHelp: 'à¤®à¤¦à¤¦ à¤•à¥‡ à¤²à¤¿à¤ à¤¤à¥ˆà¤¯à¤¾à¤°',
      startVoiceQueryTap: 'à¤†à¤µà¤¾à¤œà¤¼ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¶à¥à¤°à¥‚ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤Ÿà¥ˆà¤ª à¤•à¤°à¥‡à¤‚',
      stopRecordingBtn: 'à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤— à¤°à¥‹à¤•à¥‡à¤‚',
      startVoiceQueryBtn: 'à¤†à¤µà¤¾à¤œà¤¼ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚',
      supportedLanguages: 'à¤¸à¤®à¤°à¥à¤¥à¤¿à¤¤ à¤­à¤¾à¤·à¤¾à¤à¤‚',
      callExpert: 'à¤µà¤¿à¤¶à¥‡à¤·à¤œà¥à¤ž à¤•à¥‹ à¤•à¥‰à¤² à¤•à¤°à¥‡à¤‚',
      textChat: 'à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ à¤šà¥ˆà¤Ÿ',
      recentQueries: 'à¤¹à¤¾à¤² à¤•à¥€ à¤ªà¥‚à¤›à¤¤à¤¾à¤›',
      interactionHistory: 'à¤†à¤ªà¤•à¥€ à¤†à¤µà¤¾à¤œà¤¼ à¤‡à¤‚à¤Ÿà¤°à¥‡à¤•à¥à¤¶à¤¨ à¤”à¤° à¤œà¤µà¤¾à¤¬',
      stopAudio: 'à¤‘à¤¡à¤¿à¤¯à¥‹ à¤°à¥‹à¤•à¥‡à¤‚',
      playAudio: 'à¤‘à¤¡à¤¿à¤¯à¥‹ à¤šà¤²à¤¾à¤à¤‚',
      stop: 'à¤°à¥‹à¤•à¥‡à¤‚',
      share: 'à¤¸à¤¾à¤à¤¾ à¤•à¤°à¥‡à¤‚',
      noQueries: 'à¤…à¤­à¥€ à¤¤à¤• à¤•à¥‹à¤ˆ à¤†à¤µà¤¾à¤œà¤¼ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¨à¤¹à¥€à¤‚',
      startAsking: 'à¤•à¥ƒà¤·à¤¿ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¤•à¤° à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚'
    },
    te: {
      title: 'à°µà°¾à°¯à°¿à°¸à± à°®à°¦à±à°¦à°¤à± à°µà±à°¯à°µà°¸à±à°¥',
      description: 'à°µà°¾à°¯à°¿à°¸à± à°‡à°‚à°Ÿà°°à°¾à°•à±à°·à°¨à± à°¦à±à°µà°¾à°°à°¾ à°®à±€ à°¸à±à°¥à°¾à°¨à°¿à°• à°­à°¾à°·à°²à±‹ à°µà±à°¯à°µà°¸à°¾à°¯ à°¸à°²à°¹à°¾ à°ªà±Šà°‚à°¦à°‚à°¡à°¿',
      voiceAssistant: 'à°µà°¾à°¯à°¿à°¸à± à°…à°¸à°¿à°¸à±à°Ÿà±†à°‚à°Ÿà±',
      assistantDescription: 'à°¤à±†à°²à±à°—à±, à°¹à°¿à°‚à°¦à±€, à°‡à°‚à°—à±à°²à±€à°·à± à°®à°°à°¿à°¯à± à°ªà±à°°à°¾à°‚à°¤à±€à°¯ à°­à°¾à°·à°²à°²à±‹ à°µà±à°¯à°µà°¸à°¾à°¯à°‚, à°µà°¾à°¤à°¾à°µà°°à°£à°‚, à°ªà°¥à°•à°¾à°²à± à°²à±‡à°¦à°¾ à°µà±à°¯à°¾à°§à±à°² à°—à±à°°à°¿à°‚à°šà°¿ à°ªà±à°°à°¶à±à°¨à°²à± à°…à°¡à°—à°‚à°¡à°¿',
      recording: 'à°°à°¿à°•à°¾à°°à±à°¡à°¿à°‚à°—à±...',
      stopRecordingTap: 'à°°à°¿à°•à°¾à°°à±à°¡à°¿à°‚à°—à± à°†à°ªà°¡à°¾à°¨à°¿à°•à°¿ à°Ÿà°¾à°ªà± à°šà±‡à°¯à°‚à°¡à°¿',
      readyToHelp: 'à°¸à°¹à°¾à°¯à°¾à°¨à°¿à°•à°¿ à°¸à°¿à°¦à±à°§à°‚',
      startVoiceQueryTap: 'à°µà°¾à°¯à°¿à°¸à± à°ªà±à°°à°¶à±à°¨ à°ªà±à°°à°¾à°°à°‚à°­à°¿à°‚à°šà°¡à°¾à°¨à°¿à°•à°¿ à°Ÿà°¾à°ªà± à°šà±‡à°¯à°‚à°¡à°¿',
      stopRecordingBtn: 'à°°à°¿à°•à°¾à°°à±à°¡à°¿à°‚à°—à± à°†à°ªà°‚à°¡à°¿',
      startVoiceQueryBtn: 'à°µà°¾à°¯à°¿à°¸à± à°ªà±à°°à°¶à±à°¨ à°ªà±à°°à°¾à°°à°‚à°­à°¿à°‚à°šà°‚à°¡à°¿',
      supportedLanguages: 'à°®à°¦à±à°¦à°¤à± à°‰à°¨à±à°¨ à°­à°¾à°·à°²à±',
      callExpert: 'à°¨à°¿à°ªà±à°£à±à°¡à°¿à°•à°¿ à°•à°¾à°²à± à°šà±‡à°¯à°‚à°¡à°¿',
      textChat: 'à°Ÿà±†à°•à±à°¸à±à°Ÿà± à°šà°¾à°Ÿà±',
      recentQueries: 'à°‡à°Ÿà±€à°µà°²à°¿ à°ªà±à°°à°¶à±à°¨à°²à±',
      interactionHistory: 'à°®à±€ à°µà°¾à°¯à°¿à°¸à± à°‡à°‚à°Ÿà°°à°¾à°•à±à°·à°¨à±â€Œà°²à± à°®à°°à°¿à°¯à± à°ªà±à°°à°¤à°¿à°¸à±à°ªà°‚à°¦à°¨à°²à±',
      stopAudio: 'à°†à°¡à°¿à°¯à±‹ à°†à°ªà°‚à°¡à°¿',
      playAudio: 'à°†à°¡à°¿à°¯à±‹ à°ªà±à°²à±‡ à°šà±‡à°¯à°‚à°¡à°¿',
      stop: 'à°†à°ªà°‚à°¡à°¿',
      share: 'à°·à±‡à°°à± à°šà±‡à°¯à°‚à°¡à°¿',
      noQueries: 'à°‡à°‚à°•à°¾ à°µà°¾à°¯à°¿à°¸à± à°ªà±à°°à°¶à±à°¨à°²à± à°²à±‡à°µà±',
      startAsking: 'à°µà±à°¯à°µà°¸à°¾à°¯ à°ªà±à°°à°¶à±à°¨ à°…à°¡à°¿à°—à°¿ à°ªà±à°°à°¾à°°à°‚à°­à°¿à°‚à°šà°‚à°¡à°¿'
    },
    ta: {
      title: 'à®•à¯à®°à®²à¯ à®†à®¤à®°à®µà¯ à®…à®®à¯ˆà®ªà¯à®ªà¯',
      description: 'à®•à¯à®°à®²à¯ à®¤à¯Šà®Ÿà®°à¯à®ªà¯ à®®à¯‚à®²à®®à¯ à®‰à®™à¯à®•à®³à¯ à®‰à®³à¯à®³à¯‚à®°à¯ à®®à¯Šà®´à®¿à®¯à®¿à®²à¯ à®µà®¿à®µà®šà®¾à®¯ à®†à®²à¯‹à®šà®©à¯ˆ à®ªà¯†à®±à¯à®™à¯à®•à®³à¯',
      voiceAssistant: 'à®•à¯à®°à®²à¯ à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯',
      assistantDescription: 'à®¤à®®à®¿à®´à¯, à®‡à®¨à¯à®¤à®¿, à®†à®™à¯à®•à®¿à®²à®®à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®¿à®°à®¾à®¨à¯à®¤à®¿à®¯ à®®à¯Šà®´à®¿à®•à®³à®¿à®²à¯ à®µà®¿à®µà®šà®¾à®¯à®®à¯, à®µà®¾à®©à®¿à®²à¯ˆ, à®¤à®¿à®Ÿà¯à®Ÿà®™à¯à®•à®³à¯ à®…à®²à¯à®²à®¤à¯ à®¨à¯‹à®¯à¯à®•à®³à¯ à®ªà®±à¯à®±à®¿ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯ à®•à¯‡à®³à¯à®™à¯à®•à®³à¯',
      recording: 'à®ªà®¤à®¿à®µà¯ à®šà¯†à®¯à¯à®•à®¿à®±à®¤à¯...',
      stopRecordingTap: 'à®ªà®¤à®¿à®µà¯ à®¨à®¿à®±à¯à®¤à¯à®¤ à®¤à®Ÿà¯à®Ÿà®µà¯à®®à¯',
      readyToHelp: 'à®‰à®¤à®µà®¿à®•à¯à®•à¯ à®¤à®¯à®¾à®°à¯',
      startVoiceQueryTap: 'à®•à¯à®°à®²à¯ à®•à¯‡à®³à¯à®µà®¿ à®¤à¯Šà®Ÿà®™à¯à®• à®¤à®Ÿà¯à®Ÿà®µà¯à®®à¯',
      stopRecordingBtn: 'à®ªà®¤à®¿à®µà¯ à®¨à®¿à®±à¯à®¤à¯à®¤à¯',
      startVoiceQueryBtn: 'à®•à¯à®°à®²à¯ à®•à¯‡à®³à¯à®µà®¿ à®¤à¯Šà®Ÿà®™à¯à®•à¯',
      supportedLanguages: 'à®†à®¤à®°à®¿à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®®à¯ à®®à¯Šà®´à®¿à®•à®³à¯',
      callExpert: 'à®¨à®¿à®ªà¯à®£à®°à¯ˆ à®…à®´à¯ˆà®•à¯à®•à®µà¯à®®à¯',
      textChat: 'à®‰à®°à¯ˆ à®…à®°à®Ÿà¯à®Ÿà¯ˆ',
      recentQueries: 'à®šà®®à¯€à®ªà®¤à¯à®¤à®¿à®¯ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯',
      interactionHistory: 'à®‰à®™à¯à®•à®³à¯ à®•à¯à®°à®²à¯ à®¤à¯Šà®Ÿà®°à¯à®ªà¯à®•à®³à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®¤à®¿à®²à¯à®•à®³à¯',
      stopAudio: 'à®†à®Ÿà®¿à®¯à¯‹ à®¨à®¿à®±à¯à®¤à¯à®¤à¯',
      playAudio: 'à®†à®Ÿà®¿à®¯à¯‹ à®‡à®¯à®•à¯à®•à¯',
      stop: 'à®¨à®¿à®±à¯à®¤à¯à®¤à¯',
      share: 'à®ªà®•à®¿à®°à¯',
      noQueries: 'à®‡à®©à¯à®©à¯à®®à¯ à®•à¯à®°à®²à¯ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯ à®‡à®²à¯à®²à¯ˆ',
      startAsking: 'à®µà®¿à®µà®šà®¾à®¯ à®•à¯‡à®³à¯à®µà®¿ à®•à¯‡à®Ÿà¯à®Ÿà¯ à®¤à¯Šà®Ÿà®™à¯à®•à¯à®™à¯à®•à®³à¯'
    },
    ml: {
      title: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´¸à´ªàµà´ªàµ‹àµ¼à´Ÿàµà´Ÿàµ à´¸à´¿à´¸àµà´±àµà´±à´‚',
      description: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´‡à´¨àµà´±à´±à´¾à´•àµà´·àµ» à´µà´´à´¿ à´¨à´¿à´™àµà´™à´³àµà´Ÿàµ† à´ªàµà´°à´¾à´¦àµ‡à´¶à´¿à´• à´­à´¾à´·à´¯à´¿àµ½ à´•àµƒà´·à´¿ à´‰à´ªà´¦àµ‡à´¶à´‚ à´¨àµ‡à´Ÿàµà´•',
      voiceAssistant: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´…à´¸à´¿à´¸àµà´±àµà´±à´¨àµà´±àµ',
      assistantDescription: 'à´®à´²à´¯à´¾à´³à´‚, à´¹à´¿à´¨àµà´¦à´¿, à´‡à´‚à´—àµà´²àµ€à´·àµ, à´ªàµà´°à´¾à´¦àµ‡à´¶à´¿à´• à´­à´¾à´·à´•à´³à´¿àµ½ à´•àµƒà´·à´¿, à´•à´¾à´²à´¾à´µà´¸àµà´¥, à´ªà´¦àµà´§à´¤à´¿à´•àµ¾, à´°àµ‹à´—à´™àµà´™àµ¾ à´Žà´¨àµà´¨à´¿à´µà´¯àµ†à´•àµà´•àµà´±à´¿à´šàµà´šàµ à´šàµ‹à´¦àµà´¯à´™àµà´™àµ¾ à´šàµ‹à´¦à´¿à´•àµà´•àµà´•',
      recording: 'à´±àµ†à´•àµà´•àµ‹àµ¼à´¡à´¿à´‚à´—àµ...',
      stopRecordingTap: 'à´±àµ†à´•àµà´•àµ‹àµ¼à´¡à´¿à´‚à´—àµ à´¨à´¿àµ¼à´¤àµà´¤à´¾àµ» à´Ÿà´¾à´ªàµà´ªàµ à´šàµ†à´¯àµà´¯àµà´•',
      readyToHelp: 'à´¸à´¹à´¾à´¯à´¤àµà´¤à´¿à´¨àµ à´¤à´¯àµà´¯à´¾à´±à´¾à´£àµ',
      startVoiceQueryTap: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´šàµ‹à´¦àµà´¯à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•à´¾àµ» à´Ÿà´¾à´ªàµà´ªàµ à´šàµ†à´¯àµà´¯àµà´•',
      stopRecordingBtn: 'à´±àµ†à´•àµà´•àµ‹àµ¼à´¡à´¿à´‚à´—àµ à´¨à´¿àµ¼à´¤àµà´¤àµà´•',
      startVoiceQueryBtn: 'à´µàµ‹à´¯àµâ€Œà´¸àµ à´šàµ‹à´¦àµà´¯à´‚ à´†à´°à´‚à´­à´¿à´•àµà´•àµà´•',
      supportedLanguages: 'à´ªà´¿à´¨àµà´¤àµà´£à´¯àµà´³àµà´³ à´­à´¾à´·à´•àµ¾',
      callExpert: 'à´µà´¿à´¦à´—àµà´§à´¨àµ† à´µà´¿à´³à´¿à´•àµà´•àµà´•',
      textChat: 'à´Ÿàµ†à´•àµà´¸àµà´±àµà´±àµ à´šà´¾à´±àµà´±àµ',
      recentQueries: 'à´¸à´®àµ€à´ªà´•à´¾à´² à´šàµ‹à´¦àµà´¯à´™àµà´™àµ¾',
      interactionHistory: 'à´¨à´¿à´™àµà´™à´³àµà´Ÿàµ† à´µàµ‹à´¯àµâ€Œà´¸àµ à´‡à´¨àµà´±à´±à´¾à´•àµà´·à´¨àµà´•à´³àµà´‚ à´ªàµà´°à´¤à´¿à´•à´°à´£à´™àµà´™à´³àµà´‚',
      stopAudio: 'à´“à´¡à´¿à´¯àµ‹ à´¨à´¿àµ¼à´¤àµà´¤àµà´•',
      playAudio: 'à´“à´¡à´¿à´¯àµ‹ à´ªàµà´²àµ‡ à´šàµ†à´¯àµà´¯àµà´•',
      stop: 'à´¨à´¿àµ¼à´¤àµà´¤àµà´•',
      share: 'à´ªà´™àµà´•à´¿à´Ÿàµà´•',
      noQueries: 'à´‡à´¤àµà´µà´°àµ† à´µàµ‹à´¯àµâ€Œà´¸àµ à´šàµ‹à´¦àµà´¯à´™àµà´™à´³à´¿à´²àµà´²',
      startAsking: 'à´’à´°àµ à´•àµƒà´·à´¿ à´šàµ‹à´¦àµà´¯à´‚ à´šàµ‹à´¦à´¿à´šàµà´šàµ à´†à´°à´‚à´­à´¿à´•àµà´•àµà´•'
    }
  };

  const t = translations[currentLanguage as keyof typeof translations] || translations.en;

  const handleStartRecording = async () => {
    setIsRecording(true);
    setCurrentQuery('');
    setAiResponse('');

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      mediaStreamRef.current = stream;

      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 16000
      });
      audioContextRef.current = audioContext;

      const ws = new WebSocket(VOICE_WS_URL);
      wsRef.current = ws;

      ws.onopen = () => {
        console.log('WebSocket connection established');
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        console.log('Received:', data);
        
        if (data.type === 'partial_transcript') {
          setCurrentQuery(data.text);
        } else if (data.type === 'agent_response') {
          setAiResponse(data.text);
          // Don't auto-play browser TTS here as we'll receive agent_audio
        } else if (data.type === 'agent_audio') {
          // Play the audio data received from Deepgram
          try {
            console.log('Received agent audio data:', data.audio_data.length);
            const audioArray = new Uint8Array(data.audio_data);
            playAudioData(audioArray);
          } catch (error) {
            console.error('Error playing audio:', error);
            
            // Fallback to browser TTS if agent audio fails
            if (aiResponse) {
              const utterance = new SpeechSynthesisUtterance(aiResponse);
              utterance.lang = selectedLanguage === 'hindi' ? 'hi-IN' : 'en-IN';
              speechSynthesis.speak(utterance);
            }
          }
        }
      };

      ws.onerror = (error) => {
        console.error('WebSocket error:', error);
      };

      ws.onclose = () => {
        setIsRecording(false);
      };

      const source = audioContext.createMediaStreamSource(stream);
      
      // Create audio worklet processor
      const audioWorkletCode = `
        class AudioProcessor extends AudioWorkletProcessor {
          process(inputs, outputs, parameters) {
            const input = inputs[0];
            if (input && input.length > 0) {
              const inputData = input[0];
              
              // Convert float32 to int16 PCM
              const pcm16Data = new Int16Array(inputData.length);
              for (let i = 0; i < inputData.length; i++) {
                pcm16Data[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
              }
              
              // Send to main thread
              this.port.postMessage(pcm16Data.buffer);
            }
            return true;
          }
        }
        
        registerProcessor('audio-processor', AudioProcessor);
      `;

      // Create blob URL for the worklet
      const blob = new Blob([audioWorkletCode], { type: 'application/javascript' });
      const workletUrl = URL.createObjectURL(blob);

      try {
        await audioContext.audioWorklet.addModule(workletUrl);
        
        const workletNode = new AudioWorkletNode(audioContext, 'audio-processor');
        workletNodeRef.current = workletNode;

        // Handle messages from the worklet
        workletNode.port.onmessage = (event) => {
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(event.data);
          }
        };

        source.connect(workletNode);
        workletNode.connect(audioContext.destination);

        // Clean up blob URL
        URL.revokeObjectURL(workletUrl);
        
      } catch (workletError) {
        console.warn('AudioWorklet not supported, falling back to ScriptProcessorNode:', workletError);
        
        // Fallback to ScriptProcessorNode for older browsers
        const processor = audioContext.createScriptProcessor(4096, 1, 1);

        processor.onaudioprocess = (event) => {
          if (ws.readyState === WebSocket.OPEN) {
            const inputData = event.inputBuffer.getChannelData(0);
            
            // Convert float32 to int16 PCM
            const pcm16Data = new Int16Array(inputData.length);
            for (let i = 0; i < inputData.length; i++) {
              pcm16Data[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
            }
            
            // Send binary audio data
            ws.send(pcm16Data.buffer);
          }
        };

        source.connect(processor);
        processor.connect(audioContext.destination);
        
        // Store processor reference for cleanup
        workletNodeRef.current = processor as any;
      }
    } catch (error) {
      console.error('Error accessing microphone:', error);
      setIsRecording(false);
      toast({
        title: "Microphone Error",
        description: "Failed to access microphone. Please check permissions.",
        variant: "destructive"
      });
    }
  };

  const handleStopRecording = () => {
    setIsRecording(false);

    // Clean up audio processing
    if (workletNodeRef.current) {
      workletNodeRef.current.disconnect();
      workletNodeRef.current = null;
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => track.stop());
      mediaStreamRef.current = null;
    }

    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
  };

  const handlePlayResponse = (query: VoiceQuery) => {
    // Stop any currently playing audio
    if (isPlaying) {
      handleStopAudio();
      return;
    }

    setIsPlaying(true);
    setCurrentPlayingId(query.id);
    
    // Use Web Speech API for text-to-speech if available
    if ('speechSynthesis' in window) {
      // Cancel any existing speech
      speechSynthesis.cancel();
      
      const utterance = new SpeechSynthesisUtterance(query.response);
      utterance.lang = query.language === 'hindi' ? 'hi-IN' : 'en-IN';
      utterance.rate = 0.9; // Slightly slower for better comprehension
      utterance.pitch = 1;
      utterance.volume = 1;
      
      utterance.onend = () => {
        setIsPlaying(false);
        setCurrentPlayingId(null);
        speechSynthesisRef.current = null;
      };
      
      utterance.onerror = () => {
        setIsPlaying(false);
        setCurrentPlayingId(null);
        speechSynthesisRef.current = null;
        toast({
          title: "Audio Error",
          description: "Failed to play audio response",
          variant: "destructive"
        });
      };
      
      speechSynthesisRef.current = utterance;
      speechSynthesis.speak(utterance);
    } else {
      // Fallback simulation
      setTimeout(() => {
        setIsPlaying(false);
        setCurrentPlayingId(null);
      }, 3000);
    }
    
    toast({
      title: "Playing Response",
      description: `Playing in ${query.language}`,
    });
  };

  const handleStopAudio = () => {
    if ('speechSynthesis' in window) {
      speechSynthesis.cancel();
    }
    setIsPlaying(false);
    setCurrentPlayingId(null);
    speechSynthesisRef.current = null;
    
    toast({
      title: "Audio Stopped",
      description: "Voice playback has been stopped",
    });
  };

  const getCategoryColor = (category: string) => {
    switch (category) {
      case 'farming': return 'bg-primary/10 text-primary';
      case 'weather': return 'bg-accent/10 text-accent';
      case 'scheme': return 'bg-secondary/10 text-secondary';
      case 'disease': return 'bg-destructive/10 text-destructive';
      default: return 'bg-muted text-muted-foreground';
    }
  };

  return (
    <div className="space-y-6" id="support">
      <div className="text-center space-y-2">
        <h2 className="text-3xl font-bold text-primary">{t.title}</h2>
        <p className="text-muted-foreground">
          {t.description}
        </p>
      </div>

      <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
        {/* Voice Input Section */}
        <Card className="hover:shadow-lg transition-all duration-300">
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <Mic className="w-5 h-5 text-primary" />
              {t.voiceAssistant}
            </CardTitle>
            <CardDescription>
              {t.assistantDescription}
            </CardDescription>
          </CardHeader>
          <CardContent className="space-y-6">
            {/* Recording Interface */}
            <div className="text-center space-y-4">
              <div className={`w-24 h-24 mx-auto rounded-full flex items-center justify-center transition-all duration-300 ${
                isRecording 
                  ? 'bg-destructive/20 border-4 border-destructive animate-pulse' 
                  : 'bg-primary/20 border-4 border-primary hover:bg-primary/30'
              }`}>
                {isRecording ? (
                  <MicOff className="w-8 h-8 text-destructive" />
                ) : (
                  <Mic className="w-8 h-8 text-primary" />
                )}
              </div>
              
              <div className="space-y-2">
                {isRecording ? (
                  <>
                    <p className="text-lg font-medium text-destructive">{t.recording}</p>
                    <p className="text-sm text-muted-foreground">{t.stopRecordingTap}</p>
                  </>
                ) : (
                  <>
                    <p className="text-lg font-medium">{t.readyToHelp}</p>
                    <p className="text-sm text-muted-foreground">{t.startVoiceQueryTap}</p>
                  </>
                )}
              </div>

              <Button
                size="lg"
                variant={isRecording ? "destructive" : "hero"}
                onClick={isRecording ? handleStopRecording : handleStartRecording}
                className="w-full"
              >
                {isRecording ? (
                  <>
                    <MicOff className="w-4 h-4 mr-2" />
                    {t.stopRecordingBtn}
                  </>
                ) : (
                  <>
                    <Mic className="w-4 h-4 mr-2" />
                    {t.startVoiceQueryBtn}
                  </>
                )}
              </Button>
            </div>

            {/* Language Selection */}
            <div className="space-y-2">
              <h4 className="font-medium">{t.supportedLanguages}</h4>
              <div className="flex flex-wrap gap-2">
                {[
                  { code: 'hindi', name: 'à¤¹à¤¿à¤¨à¥à¤¦à¥€', flag: 'ðŸ‡®ðŸ‡³' },
                  { code: 'english', name: 'English', flag: 'ðŸ‡¬ðŸ‡§' },
                  { code: 'punjabi', name: 'à¨ªà©°à¨œà¨¾à¨¬à©€', flag: 'ðŸ‡®ðŸ‡³' },
                  { code: 'telugu', name: 'à°¤à±†à°²à±à°—à±', flag: 'ðŸ‡®ðŸ‡³' },
                  { code: 'tamil', name: 'à®¤à®®à®¿à®´à¯', flag: 'ðŸ‡®ðŸ‡³' },
                ].map((lang) => (
                  <Button
                    key={lang.code}
                    variant={selectedLanguage === lang.code ? "default" : "outline"}
                    size="sm"
                    onClick={() => setSelectedLanguage(lang.code)}
                  >
                    {lang.flag} {lang.name}
                  </Button>
                ))}
              </div>
            </div>

            {/* Quick Actions */}
            <div className="grid grid-cols-2 gap-2">
              <Button variant="outline" size="sm">
                <Phone className="w-4 h-4 mr-2" />
                {t.callExpert}
              </Button>
              <Button variant="outline" size="sm">
                <MessageSquare className="w-4 h-4 mr-2" />
                {t.textChat}
              </Button>
            </div>
          </CardContent>
        </Card>

        {/* Query History */}
        <Card className="hover:shadow-lg transition-all duration-300">
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <MessageSquare className="w-5 h-5 text-accent" />
              {t.recentQueries}
            </CardTitle>
            <CardDescription>
              {t.interactionHistory}
            </CardDescription>
          </CardHeader>
          <CardContent className="space-y-4">
            {voiceQueries.length > 0 ? (
              voiceQueries.map((query) => (
                <div key={query.id} className="space-y-3 p-4 bg-muted/30 rounded-lg">
                  <div className="flex items-start justify-between">
                    <div className="space-y-1 flex-1">
                      <div className="flex items-center gap-2">
                        <Badge className={getCategoryColor(query.category)} variant="secondary">
                          {query.category}
                        </Badge>
                        <span className="text-xs text-muted-foreground">
                          {query.timestamp.toLocaleTimeString()}
                        </span>
                      </div>
                      <p className="text-sm font-medium">{query.query}</p>
                    </div>
                  </div>
                  
                  <div className="bg-primary/5 p-3 rounded border-l-4 border-primary">
                    <p className="text-sm">{query.response}</p>
                  </div>
                  
                  <div className="flex gap-2">
                    <Button 
                      variant="outline" 
                      size="sm"
                      onClick={() => handlePlayResponse(query)}
                    >
                      {isPlaying && currentPlayingId === query.id ? (
                        <>
                          <Pause className="w-3 h-3 mr-1" />
                          {t.stopAudio}
                        </>
                      ) : (
                        <>
                          <Volume2 className="w-3 h-3 mr-1" />
                          {t.playAudio}
                        </>
                      )}
                    </Button>
                    {isPlaying && currentPlayingId === query.id && (
                      <Button 
                        variant="destructive" 
                        size="sm"
                        onClick={handleStopAudio}
                      >
                        <VolumeX className="w-3 h-3 mr-1" />
                        {t.stop}
                      </Button>
                    )}
                    <Button variant="ghost" size="sm">
                      {t.share}
                    </Button>
                  </div>
                </div>
              ))
            ) : (
              <div className="text-center py-8 text-muted-foreground">
                <MessageSquare className="w-12 h-12 mx-auto mb-3 opacity-50" />
                <p>{t.noQueries}</p>
                <p className="text-sm mt-1">{t.startAsking}</p>
              </div>
            )}
          </CardContent>
        </Card>
      </div>
    </div>
  );
};

export default VoiceSupport;

